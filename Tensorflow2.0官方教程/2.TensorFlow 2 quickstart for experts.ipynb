{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.TensorFlow 2 quickstart for experts.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNablGSwR79FyQuiEtjbx0Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"GttGWsUVAg77","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633396661001,"user_tz":-480,"elapsed":4394,"user":{"displayName":"Liao Jack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16157886839679822522"}},"outputId":"5335616f-b84f-439a-b434-d8aeea30813b"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D\n","from tensorflow.keras import Model\n","\n","#加载并准备 MNIST 数据集\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","# Add a channels dimension\n","x_train = x_train[..., tf.newaxis]\n","x_test = x_test[..., tf.newaxis]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"-2VoB5PdButN"},"source":["#使用 tf.data 来将数据集切分为 batch 以及混淆数据集\n","train_ds = tf.data.Dataset.from_tensor_slices(\n","    (x_train, y_train)).shuffle(10000).batch(32)\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zRG-xCCjCBcj"},"source":["#使用 Keras 模型子类化（model subclassing） API 构建 tf.keras 模型\n","class MyModel(Model):\n","  def __init__(self):\n","    super(MyModel, self).__init__()\n","    self.conv1 = Conv2D(32, 3, activation='relu')\n","    self.flatten = Flatten()\n","    self.d1 = Dense(128, activation='relu')\n","    self.d2 = Dense(10, activation='softmax')\n","\n","  def call(self, x):\n","    x = self.conv1(x)\n","    x = self.flatten(x)\n","    x = self.d1(x)\n","    return self.d2(x)\n","\n","model = MyModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HNNV3BtOCMAi"},"source":["#为训练选择优化器与损失函数\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()\n","\n","#选择衡量指标来度量模型的损失值（loss）和准确率（accuracy）。这些指标在 epoch 上累积值，然后打印出整体结果。\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APOlO6HJCfwE","executionInfo":{"status":"ok","timestamp":1633397266481,"user_tz":-480,"elapsed":72275,"user":{"displayName":"Liao Jack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16157886839679822522"}},"outputId":"5bf11d31-606b-45da-ac8d-73909ff232af"},"source":["#使用 tf.GradientTape 来训练模型\n","@tf.function\n","def train_step(images, labels):\n","  with tf.GradientTape() as tape:\n","    predictions = model(images)\n","    loss = loss_object(labels, predictions)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)\n","\n","#测试模型\n","@tf.function\n","def test_step(images, labels):\n","  predictions = model(images)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss(t_loss)\n","  test_accuracy(labels, predictions)\n","\n","EPOCHS = 5\n","\n","for epoch in range(EPOCHS):\n","  # 在下一个epoch开始时，重置评估指标\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  test_accuracy.reset_states()\n","\n","  for images, labels in train_ds:\n","    train_step(images, labels)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(test_images, test_labels)\n","\n","  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n","  print (template.format(epoch+1,\n","              train_loss.result(),\n","              train_accuracy.result()*100,\n","              test_loss.result(),\n","              test_accuracy.result()*100))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.13838960230350494, Accuracy: 95.86666870117188, Test Loss: 0.05856192111968994, Test Accuracy: 98.06999969482422\n","Epoch 2, Loss: 0.04270603135228157, Accuracy: 98.68500518798828, Test Loss: 0.050201259553432465, Test Accuracy: 98.31999969482422\n","Epoch 3, Loss: 0.022439351305365562, Accuracy: 99.28666687011719, Test Loss: 0.05785330384969711, Test Accuracy: 98.27999877929688\n","Epoch 4, Loss: 0.013116580434143543, Accuracy: 99.57833099365234, Test Loss: 0.05482617765665054, Test Accuracy: 98.37999725341797\n","Epoch 5, Loss: 0.008930186741054058, Accuracy: 99.70500183105469, Test Loss: 0.06779646873474121, Test Accuracy: 98.32999420166016\n"]}]}]}